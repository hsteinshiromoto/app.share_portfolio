stages:
    - build_container
    - run_container
    - test_make_dataset
    - deploy_container

# ---
# CI Setup
# ---

variables:
  image_name: 'registry.gitlab.com/hsteinshiromoto/app.share_portfolio:latest'
  REMOTE_FOLDER: "~"

# ---
# Build Stage
# ---

# Build and push container to gitlab registry
# Note that it requires to login to Docker hub as one image is private from there
# src: https://imil.net/blog/2018/11/04/From-GitLab-CI-to-Docker-Hub/

build_container:
  # Image to use the command "docker"
  stage: build_container
  only:
    - dev
    - master
  image: docker:stable
  # Start service to have access to Docker binaries
  services:
    - docker:dind
  # Need to install make. Note that the default Gitlab 
  # container Linux distro is Alpine.
  before_script:
    - apk add bash make git
    # - docker login -u $DOCKER_HUB_USER -p "$DOCKER_HUB_PWD" $DOCKER_HUB_REGISTRY
  script:
    - make build
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker push $image_name

# ---
# Run Stage
# ---

# Run container

run_container:
  # Image to use the command "docker"
  stage: run_container
  only:
    - dev
    - master
  image: docker:stable
  # Start service to have access to Docker binaries
  services:
    - docker:dind
  # Need to install make. Note that the default Gitlab 
  # container Linux distro is Alpine.
  before_script:
    - apk add bash make git
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker pull $image_name
    - sh run_container.sh $image_name

# ---
# Tests Stage
# ---

# Test make_dataset.py

test_make_dataset:
  stage: test_make_dataset
  only:
    - dev
    - master
  # Need to install make. Note that the default Gitlab
  # container Linux distro is Alpine.
  image: $image_name
  before_script:
    - export PYTHONPATH=${PWD}
  script:
    - python3 src/tests/test_make_dataset.py

# ---
# Deploy Stage
# ---

deploy_container:
  # Image to use the command "docker"
  stage: deploy_container
  only:
    - dev
    - master
    - feature/deploy_AWS
  image: docker:stable
  # Start service to have access to Docker binaries
  services:
    - docker:dind
  # Need to install make. Note that the default Gitlab 
  # container Linux distro is Alpine.
  before_script:
    # Install packages in host
    - apk add bash make git openssh

    # Prepare SSH key
    - mkdir -p ~/.ssh
    - echo "-----BEGIN RSA PRIVATE KEY-----" > ~/.ssh/key.pem
    - echo $AWS_SSH | sed -e 's/-----BEGIN RSA PRIVATE KEY-----\(.*\)-----END RSA PRIVATE KEY-----/\1/' |  tr " " "\n" | tail -c +2 | head -c -1 >> ~/.ssh/key.pem
    - echo "-----END RSA PRIVATE KEY-----" >> ~/.ssh/key.pem
    - chmod 700 ~/.ssh
    - chmod 400 ~/.ssh/key.pem
    - echo "export CI_REGISTRY_USER=$CI_REGISTRY_USER" > ~/.bashrc
    - echo "export CI_REGISTRY_PASSWORD=$CI_REGISTRY_PASSWORD" >> ~/.bashrc
    - echo "export CI_REGISTRY=$CI_REGISTRY" >> ~/.bashrc
    - ssh -o "StrictHostKeyChecking no" -i ~/.ssh/key.pem -t -t $HOST_USER@$HOST_ADDRESS 'sudo apt-get update && sudo apt-get upgrade -y && sudo apt-get install docker.io -y'
    - ssh -o "StrictHostKeyChecking no" -i ~/.ssh/key.pem -t -t $HOST_USER@$HOST_ADDRESS 'sudo usermod -aG docker $USER'
    - ssh -o "StrictHostKeyChecking no" -i ~/.ssh/key.pem -t -t $HOST_USER@$HOST_ADDRESS 'sudo setfacl -m user:$USER:rw /var/run/docker.sock'

  script:
    # - scp deploy.sh $HOST_USER@:$HOST_ADDRESS:REMOTE_FOLDER
    - scp -i ~/.ssh/key.pem ~/.bashrc $HOST_USER@$HOST_ADDRESS:~
    # - ssh -i ~/.ssh/key.pem $HOST_USER@$HOST_ADDRESS -t -t 'source ~/.bashrc'
    - ssh -i ~/.ssh/key.pem $HOST_USER@$HOST_ADDRESS -t -t "docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY"
    - ssh -i ~/.ssh/key.pem $HOST_USER@$HOST_ADDRESS -t -t 'docker pull $image_name'
    - ssh -i ~/.ssh/key.pem $HOST_USER@$HOST_ADDRESS -t -t 'docker run -p 80:5000 $image_name'
